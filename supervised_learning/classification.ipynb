{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TYPES OF CLASSIFICATION\n",
    "+ Binary  \n",
    "+ Multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ACCURACY\n",
    "Accuracy= `No of correct predictions/Total no of inputs`   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CONFUSION MATRIX\n",
    "\n",
    "|            |Predicted T|Predicted F|\n",
    "|------------|-----------|-----------|\n",
    "|**Actual T**|TP         |FN         |\n",
    "|**Actual F**|FP         |TN         |\n",
    "\n",
    "\n",
    "\n",
    "+ Accuracy  \n",
    "`TP+TN / TP+TN+FP+FN`  \n",
    "\n",
    "+ Precision  \n",
    "`TP / TP+FP`  \n",
    "TP divide by total no of positives.  \n",
    "How accurate +ve predictions are.  \n",
    "Used to minimize **FP**  \n",
    "Eg classify non spam as spam.  \n",
    "\n",
    "+ Recall/TPR  \n",
    "`TP / TP+FN`  \n",
    "TP divide by the real/accurate positives.  \n",
    "How it correctly identifies positive cases.  \n",
    "Used to minimize **FN**  \n",
    "Eg medical, must get all positives even if it will have FP as well.  \n",
    "\n",
    "+ F1-Score  \n",
    "`2*P*R / P+R`  \n",
    "Harmonic mean of precison and recall.  \n",
    "\n",
    "+ Specificity/TNR  \n",
    "`TN / TN+FP`  \n",
    "TN divide by the real/accirate negatives.  \n",
    "How it correctly identifies negative cases.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, ConfusionMatrixDisplay, classification_report\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Actual labels\n",
    "y_true = ['Cat'] * 10 + ['Dog'] * 12 + ['Horse'] * 10\n",
    "# Predicted labels \n",
    "y_pred = ['Cat'] * 8 + ['Dog'] + ['Horse'] + ['Cat'] * 2 + ['Dog'] * 10 + ['Horse'] * 8 + ['Dog'] * 2\n",
    "# Classes\n",
    "classes = ['Cat', 'Dog', 'Horse']\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix', fontsize=15, pad=20)\n",
    "plt.xlabel('Prediction', fontsize=11)\n",
    "plt.ylabel('Actual', fontsize=11)\n",
    "#Customizations\n",
    "plt.gca().xaxis.set_label_position('top')\n",
    "plt.gca().xaxis.tick_top()\n",
    "plt.gca().figure.subplots_adjust(bottom=0.2)\n",
    "plt.gca().figure.text(0.5, 0.05, 'Prediction', ha='center', fontsize=13)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_true, y_pred, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
